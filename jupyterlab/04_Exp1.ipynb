{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6a8c0c-010c-4c34-a0f8-b571a02d8e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt2-xl', 'gpt2-xl-untrained_1', 'gpt2', 'gpt2-untrained_1', 'gpt2-untrained_2', 'gpt2-untrained_3', 'gpt2-untrained_4', 'gpt2-untrained_5', 'gpt2-untrained_6', 'gpt2-untrained_7', 'gpt2-untrained_8', 'gpt2-untrained_9', 'gpt2-untrained_1_weight_config_all', 'gpt2-untrained_2_weight_config_all', 'gpt2-untrained_3_weight_config_all', 'gpt2-untrained_4_weight_config_all', 'gpt2-untrained_5_weight_config_all', 'gpt2-untrained_6_weight_config_all', 'gpt2-untrained_7_weight_config_all', 'gpt2-untrained_8_weight_config_all', 'gpt2-untrained_9_weight_config_all']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2789263b3a04592b9f9687c12cf6aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading mydatadict:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52   = number of possible targets\n",
      "y shape: (7958,)\n",
      "Size of ys: 0.004186046 GB\n",
      "====================================================================================================\n",
      "\n",
      "classification_labels: {\n",
      "  \"words\": ['side' 'was' 'intertwined' ... 'four' 'years' '.'],\n",
      "  \"words-\": ['.' 'side' 'was' ... ',' 'four' 'years'],\n",
      "  \"words+\": ['was' 'intertwined' '.' ... 'years' '.' 'side'],\n",
      "  \"word_idx\": [ 386  387  388 ... 8341 8342 8343],\n",
      "  \"word_idx-\": [8343  386  387 ... 8340 8341 8342],\n",
      "  \"word_idx+\": [ 387  388  389 ... 8342 8343  386],\n",
      "  \"predicate_lemmas\": ['nan' 'be' 'intertwine' ... 'nan' 'nan' 'nan'],\n",
      "  \"predicate_lemmas-\": ['nan' 'nan' 'be' ... 'nan' 'nan' 'nan'],\n",
      "  \"predicate_lemmas+\": ['be' 'intertwine' 'nan' ... 'nan' 'nan' 'nan'],\n",
      "  \"predicate_framenet_ids\": ['nan' '03' '01' ... 'nan' 'nan' 'nan'],\n",
      "  \"predicate_framenet_ids-\": ['nan' 'nan' '03' ... 'nan' 'nan' 'nan'],\n",
      "  \"predicate_framenet_ids+\": ['03' '01' 'nan' ... 'nan' 'nan' 'nan'],\n",
      "  \"word_senses\": [nan nan nan ... nan nan nan],\n",
      "  \"word_senses-\": [nan nan nan ... nan nan nan],\n",
      "  \"word_senses+\": [nan nan nan ... nan nan nan],\n",
      "  \"named_entities\": [ 0  0  0 ... 15 16  0],\n",
      "  \"named_entities-\": [ 0  0  0 ...  0 15 16],\n",
      "  \"named_entities+\": [ 0  0  0 ... 16  0  0],\n",
      "  \"function\": [0 1 0 ... 0 0 2],\n",
      "  \"function-\": [2 0 1 ... 2 0 0],\n",
      "  \"function+\": [1 0 2 ... 0 2 0],\n",
      "  \"tree_depth\": [7 4 5 ... 7 7 3],\n",
      "  \"tree_depth-\": [3 7 4 ... 6 7 7],\n",
      "  \"tree_depth+\": [4 5 3 ... 7 3 7],\n",
      "}\n",
      "\n",
      "reggression_labels: {\n",
      "  \"sentence_idx\": [ 22  22  22 ... 499 499 499],\n",
      "  \"sentence_idx-\": [499  22  22 ... 499 499 499],\n",
      "  \"sentence_idx+\": [ 22  22  22 ... 499 499  22],\n",
      "  \"unigram_probs\": [ 8.4857895   5.2290224  12.4491967  ...  8.03694953  6.79543242\n",
      "  3.20965947],\n",
      "  \"unigram_probs-\": [3.20965947 8.4857895  5.2290224  ... 3.14589602 8.03694953 6.79543242],\n",
      "  \"unigram_probs+\": [ 5.2290224  12.4491967   3.20965947 ...  6.79543242  3.20965947\n",
      "  8.4857895 ],\n",
      "  \"bigram_probs\": [12.2330848  13.45686024 14.37315097 ... 11.60056225 10.44132533\n",
      "  8.77658258],\n",
      "  \"bigram_probs-\": [ 8.77658258 12.2330848  13.45686024 ... 11.30509803 11.60056225\n",
      " 10.44132533],\n",
      "  \"bigram_probs+\": [13.45686024 14.37315097 14.37315097 ... 10.44132533  8.77658258\n",
      " 12.2330848 ],\n",
      "  \"trigram_probs\": [14.63517078 14.63517078 14.63517078 ... 14.63517078 13.71888005\n",
      " 12.33258569],\n",
      "  \"trigram_probs-\": [12.33258569 14.63517078 14.63517078 ... 14.63517078 14.63517078\n",
      " 13.71888005],\n",
      "  \"trigram_probs+\": [14.63517078 14.63517078 14.63517078 ... 13.71888005 12.33258569\n",
      " 14.63517078],\n",
      "}\n",
      "\n",
      "pos_labels: {\n",
      "  \"pos_tags\": [25 41 43 ... 13 28  8],\n",
      "  \"pos_tags-\": [ 8 25 41 ...  5 13 28],\n",
      "  \"pos_tags+\": [41 43  8 ... 28  8 25],\n",
      "  \"POS_12_id\": [ 1  0  0 ...  8  1 11],\n",
      "  \"POS_12_id-\": [11  1  0 ... 11  8  1],\n",
      "  \"POS_12_id+\": [ 0  0 11 ...  1 11  1],\n",
      "  \"POS_7_id\": [0 1 1 ... 6 0 6],\n",
      "  \"POS_7_id-\": [6 0 1 ... 6 6 0],\n",
      "  \"POS_7_id+\": [1 1 6 ... 0 6 0],\n",
      "}\n",
      "\\other_labels: {\n",
      "  \"word_order\": [ 9 10 11 ...  7  8  9],\n",
      "  \"pos_names\": ['NN' 'VBD' 'VBN' ... 'CD' 'NNS' '.'],\n",
      "  \"POS_51\": ['NN' 'VBD' 'VBN' ... 'CD' 'NNS' '.'],\n",
      "  \"POS_12\": ['NOUN' 'VERB' 'VERB' ... 'NUM' 'NOUN' '.'],\n",
      "  \"POS_7\": ['Noun' 'Verb' 'Verb' ... 'X' 'Noun' 'X'],\n",
      "  \"POS_51_id\": [25 41 43 ... 13 28  8],\n",
      "  \"is_in_POS_6\": [ True  True  True ... False  True False],\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be75de6a587d4e389f5fc12075872b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading models:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./Preamble.ipynb\n",
    "\n",
    "all_models = PM.check_for_existing_patterns(\"activations\")\n",
    "# Uncomment below lines to use specific model sets:\n",
    "# all_models=PM.gpt2xl_models\n",
    "# all_models=PM.gpt2_models\n",
    "# all_models=['gpt2','gpt2-untrained_1','gpt2-untrained_1_weight_config_all']\n",
    "print(all_models)\n",
    "\n",
    "## load preprocessed data\n",
    "ys = PM.load_ys(v=1) # , use_cache=False)\n",
    "Xss = PM.load_Xss(all_models, v=0) # , use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26012008-a1e1-469f-a4b1-51d992a72a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data adjustments\n",
    "\n",
    "# Cap values for specific target variables (word_idx, tree_depth) to predefined limits\n",
    "for y in [\"word_idx\", \"word_idx+\", \"word_idx-\"]:\n",
    "    ys[y] = np.array([x if x <= 34 else 34 for x in ys[y]])  # Cap word index to 34\n",
    "\n",
    "for y in [\"tree_depth\", \"tree_depth+\", \"tree_depth-\"]:\n",
    "    ys[y] = np.array([x if x <= 14 else 14 for x in ys[y]])  # Cap tree depth to 14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11beb31-cc55-4aa0-ab00-d745a7e81cd7",
   "metadata": {},
   "source": [
    "## scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de92c7fb-b492-47a2-9b16-e9064bc3ff24",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7664845a98554f19abcc2162370dfe20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5462ea54f34562add91083236d5458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c4b102034049419e2e776212459cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3bbc66273a43f7835b7c8643444d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81fa7feb4ab40aca96e96117793442b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f585b15d92d45bea0317f58cf28e4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()  # Apply Intel optimizations to scikit-learn\n",
    "# https://stackoverflow.com/a/6929403\n",
    "# https://intel.github.io/scikit-learn-intelex/algorithms.html\n",
    "# https://github.com/intel/scikit-learn-intelex\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate, KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix as calc_confusion_matrix, f1_score as calc_f1_score, accuracy_score as calc_accuracy_score, make_scorer\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Define Pearson correlation scorer for regression tasks\n",
    "pearson_r_regression_scorer = make_scorer(lambda y1, y2: pearsonr(y1, y2)[0])\n",
    "\n",
    "# Cross-validation strategies\n",
    "cv_KFold = KFold(n_splits=5)\n",
    "cv_StratifiedKFold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Helper function to iterate over models, layers, and targets\n",
    "def get_input_coordinates(targets=None, models=None, model_layers_filter=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Yield (target, model, layer) combinations based on available models and targets.\n",
    "\n",
    "    Args:\n",
    "        targets (list): List of target variables to iterate over. Defaults to regression labels.\n",
    "        models (list): List of models to iterate over. Defaults to all loaded models.\n",
    "        model_layers_filter (list): Filter layers if only specific layers should be used.\n",
    "\n",
    "    Yields:\n",
    "        tuple: (target, model, layer) combinations.\n",
    "    \"\"\"\n",
    "    global ys, Xss\n",
    "    targets = targets if targets else globals()['reggression_labels']\n",
    "    models = models if models else globals()['all_models']\n",
    "    \n",
    "    for target in targets:\n",
    "        for model in models:\n",
    "            model_layers = list(Xss[model])\n",
    "            if model_layers_filter:\n",
    "                model_layers = [x for i, x in enumerate(model_layers) if i in model_layers_filter]\n",
    "            for layer in model_layers:\n",
    "                yield (target, model, layer)\n",
    "\n",
    "\n",
    "# Function to compute scores for all (target, model, layer) combinations\n",
    "def score_all(target=None, model=None, layer=None, svm_model=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute scores for all (target, model, layer) combinations using the provided SVM model.\n",
    "\n",
    "    Args:\n",
    "        target, model, layer: Specific combinations to evaluate (defaults to None).\n",
    "        svm_model (object): SVM model (e.g., LinearRegression, LogisticRegression, etc.).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Scores for all input combinations.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        (target, model, layer, str(svm_model)): \n",
    "        score_and_fit_svm_model(target=target, model=model, layer=layer, svm_model=svm_model, **kwargs)\n",
    "        for target, model, layer in tqdm(list(get_input_coordinates(**kwargs)))\n",
    "    }\n",
    "\n",
    "\n",
    "# Function to fit and score a model using cross-validation\n",
    "def score_and_fit_svm_model(target=0, model=None, layer=0, max_instances=500, svm_model=None, v=0, time=0, use_cache=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Fit and score an SVM model using cross-validation. Supports both regression and classification.\n",
    "\n",
    "    Args:\n",
    "        target (str): Target variable name.\n",
    "        model (str): Model name.\n",
    "        layer (str): Model layer name.\n",
    "        max_instances (int): Maximum number of instances to use for fitting.\n",
    "        svm_model (object): The SVM model to fit (e.g., LinearRegression, LogisticRegression).\n",
    "        v (int): Verbosity level for printing (default is 0).\n",
    "        time (bool): Whether to time the fitting process (default is False).\n",
    "        use_cache (bool): Whether to use cached results (default is True).\n",
    "\n",
    "    Returns:\n",
    "        float: The computed score (e.g., accuracy for classification or Pearson correlation for regression).\n",
    "    \"\"\"\n",
    "    # File paths for saving scores and predictions\n",
    "    score_save_name = f\"{HOME}/data/experiment_1_results/{model},{target},{layer},{max_instances},{str(svm_model)},v2.csv\"\n",
    "    predict_save_name = f\"{HOME}/data/experiment_1_results/{model},{target},{layer},{max_instances},{str(svm_model)},v2.npz\"\n",
    "    \n",
    "    # Try to load from cache if use_cache is enabled\n",
    "    try:\n",
    "        if use_cache:\n",
    "            df = pd.read_csv(score_save_name)\n",
    "            return df[\"score\"][0]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Limit the number of instances and extract the data\n",
    "    X = Xss[model][layer][:max_instances]\n",
    "    y = ys[target][:max_instances]\n",
    "\n",
    "    if isinstance(svm_model, LinearRegression):\n",
    "        # For regression tasks (Pearson correlation)\n",
    "        scores = cross_val_score(svm_model, X, y, cv=cv_KFold, n_jobs=-1, scoring=pearson_r_regression_scorer)\n",
    "        pearson_r_score = np.mean(scores)\n",
    "        pearson_r_error = np.std(scores) / np.sqrt(len(scores))\n",
    "        print(f\"pearson_r_score: {pearson_r_score}, err={pearson_r_error}\")\n",
    "\n",
    "        # Save results\n",
    "        np.savez(predict_save_name, scores=scores, pearson_r_score=pearson_r_error, pearson_r_error=pearson_r_error)\n",
    "        score = pearson_r_score\n",
    "    \n",
    "    elif isinstance(svm_model, (svm.LinearSVC, svm.SVC, LogisticRegression)):\n",
    "        # For classification tasks (accuracy score)\n",
    "        predictions = cross_val_predict(svm_model, X, y, cv=cv_StratifiedKFold, n_jobs=-1)\n",
    "        confusion_matrix = calc_confusion_matrix(y, predictions)\n",
    "        print(\"confusion_matrix:\")\n",
    "        print(confusion_matrix)\n",
    "        accuracy_score = calc_accuracy_score(y, predictions)\n",
    "        print(f\"accuracy_score: {accuracy_score}\")\n",
    "\n",
    "        # Save results\n",
    "        np.savez(predict_save_name, predictions=predictions, confusion_matrix=confusion_matrix, accuracy_score=accuracy_score)\n",
    "        score = accuracy_score\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected predictor: {svm_model}\")\n",
    "    \n",
    "    # Verbose output\n",
    "    if v == 1:\n",
    "        print(f\"score = {score}\")\n",
    "    elif v == 2:\n",
    "        print(f\"target={target}, model={model}, layer={layer}, score={score}\")\n",
    "    \n",
    "    # Save the score to a CSV file\n",
    "    df = pd.DataFrame({\n",
    "        \"model\": [model],\n",
    "        \"target\": [target],\n",
    "        \"layer\": [layer],\n",
    "        \"max_instances\": [max_instances],\n",
    "        \"v\": [v],\n",
    "        \"score\": [score]\n",
    "    })\n",
    "    df.to_csv(score_save_name, index=False)\n",
    "    return score\n",
    "\n",
    "\n",
    "# Models to test\n",
    "Linear = LinearRegression()\n",
    "SVC_model = svm.SVC(kernel='linear')\n",
    "SVR_model = svm.SVR(kernel='linear')\n",
    "Logistic1 = LogisticRegression(random_state=1, penalty=\"l1\", solver=\"saga\", tol=0.1, max_iter=1000)\n",
    "Logistic2 = LogisticRegression(random_state=1, tol=0.1, solver=\"newton-cg\", max_iter=1000)\n",
    "Logistic3 = LogisticRegression(random_state=1, penalty=\"l1\", solver=\"saga\", tol=0.1, warm_start=True)\n",
    "Logistic4 = LogisticRegression(random_state=1, tol=0.1, solver=\"newton-cg\", warm_start=True)\n",
    "LinearSVC_model = svm.LinearSVC()\n",
    "\n",
    "svm_labels = [str(x) for x in [Linear, SVC_model, SVR_model, Logistic1, Logistic2, Logistic3, Logistic4, LinearSVC_model]]\n",
    "\n",
    "use_cache = True  # Enables the use of cached results\n",
    "\n",
    "# Score the models on different target variables\n",
    "res_pos_classification_Logistic2 = score_all(targets=my_classification_targets, max_instances=10000, svm_model=Logistic1, use_cache=use_cache)\n",
    "res_regression = score_all(targets=reggression_labels, max_instances=10000, svm_model=Linear, use_cache=use_cache)\n",
    "res_pos_classification_Logistic1 = score_all(targets=pos_labels, max_instances=10000, svm_model=Logistic1, use_cache=use_cache)\n",
    "\n",
    "    \n",
    "Linear=LinearRegression()\n",
    "SVC_model=svm.SVC(kernel='linear')\n",
    "SVR_model=svm.SVR(kernel='linear')\n",
    "Logistic1=LogisticRegression(random_state=1,penalty=\"l1\",solver=\"saga\",tol=.1,max_iter=1000)\n",
    "Logistic2=LogisticRegression(random_state=1,tol=.1,solver=\"newton-cg\",max_iter=1000)\n",
    "Logistic3=LogisticRegression(random_state=1,penalty=\"l1\",solver=\"saga\",tol=.1,warm_start=True)\n",
    "Logistic4=LogisticRegression(random_state=1,tol=.1,solver=\"newton-cg\",warm_start=True)\n",
    "LinearSVC_model=svm.LinearSVC()\n",
    "\n",
    "svm_labels=[str(x) for x in [Linear,SVC_model,SVR_model,Logistic1,Logistic2,Logistic3,Logistic4,LinearSVC_model]]\n",
    "\n",
    "use_cache=True\n",
    "# use_cache=False\n",
    "\n",
    "res_reggresion = score_all(targets=reggression_labels, max_instances=10000,svm_model=Linear, use_cache=use_cache)\n",
    "res_pos_classification_Logistic1 = score_all(targets=pos_labels, max_instances=10000,svm_model=Logistic1, use_cache=use_cache)\n",
    "res_pos_classification_Logistic2 = score_all(targets=my_classification_targets, max_instances=10000,svm_model=Logistic1, use_cache=use_cache)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec0078-eafc-4ccd-b776-6a8661574980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trans_gpu",
   "language": "python",
   "name": "trans_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
